{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install textblob\n",
    "!{sys.executable} -m textblob.download_corpora lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load clean_data.py\n",
    "\"\"\"Cleaning comments dataset.\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import json\n",
    "import datetime as dt\n",
    "import difflib\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "with open('lib/data/normies-dump.csv') as f:\n",
    "    my_data = pd.read_csv(f, sep='|', dtype={\n",
    "        \"banned_by\": str,\n",
    "        \"no_follow\": str,\n",
    "        \"link_id\": str,\n",
    "        \"gilded\": str,\n",
    "        \"author\": str,\n",
    "        \"author_verified\": str,\n",
    "        \"author_comment_karma\": np.float64,\n",
    "        \"author_link_karma\": np.float64,\n",
    "        \"num_comments\": np.float64,\n",
    "        \"created_utc\": np.float64,\n",
    "        \"score\": np.float64,\n",
    "        \"over_18\": str,\n",
    "        \"body\": str,\n",
    "        \"downs\": np.float64,\n",
    "        \"is_submitter\": str,\n",
    "        \"num_reports\": np.float64,\n",
    "        \"controversiality\": np.float64,\n",
    "        \"quarantine\": str,\n",
    "        \"ups\": np.float64,\n",
    "        \"is_bot\": str,\n",
    "        \"is_troll\": str,\n",
    "        \"recent_comments\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete columns that have missing data or won't have meaningful values in real-time data\n",
    "columns = ['parent_id_ranked', 'banned_by', 'downs', 'quarantine', 'num_reports', 'num_comments', 'score', 'ups', 'controversiality', 'gilded']\n",
    "my_data.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "# drop duplicates\n",
    "dupes = len(my_data)\n",
    "my_data = my_data.drop_duplicates(subset=['author','link_id','created_utc'])\n",
    "print(\"Duplicates: \", dupes - len(my_data))\n",
    "\n",
    "# remove escape characters to make parsing easier\n",
    "my_data['recent_comments'] = my_data['recent_comments'].str.replace('\\\\','');\n",
    "\n",
    "# format columns\n",
    "my_data['created_utc'] = pd.to_datetime(my_data['created_utc'].values, unit='s')\n",
    "my_data['body'] = my_data['body'].str.slice(stop=200).fillna('')\n",
    "my_data['is_bot'] = my_data['is_bot'].map({'t':True}).fillna(False)\n",
    "my_data['is_troll'] = my_data['is_troll'].map({'t':True, 'f':False}).fillna(False)\n",
    "my_data['is_troll'] = my_data['is_troll'].map({'t':True, 'f':False}).fillna(False)\n",
    "my_data['over_18'] = my_data['over_18'].map({'t':True, 'f':False}).fillna(False)\n",
    "my_data['is_submitter'] = my_data['is_submitter'].map({'t':True, 'f':False}).fillna(False)\n",
    "my_data['author_verified'] = my_data['author_verified'].map({'t':True, 'f':False}).fillna(False)\n",
    "my_data['no_follow'] = my_data['no_follow'].map({'t':True, 'f':False}).fillna(False)\n",
    "\n",
    "# add our new stats columns\n",
    "my_data['recent_num_comments'] = pd.Series(np.zeros(len(my_data.index), np.int64))\n",
    "my_data['recent_num_last_30_days'] = pd.Series(np.zeros(len(my_data.index), np.int64))\n",
    "my_data['recent_avg_no_follow'] = pd.Series(np.zeros(len(my_data.index), np.float64))\n",
    "my_data['recent_avg_gilded'] = pd.Series(np.zeros(len(my_data.index), np.float64))\n",
    "my_data['recent_avg_responses'] = pd.Series(np.zeros(len(my_data.index), np.float64))\n",
    "my_data['recent_percent_neg_score'] = pd.Series(np.zeros(len(my_data.index), np.float64))\n",
    "my_data['recent_avg_score'] = pd.Series(np.zeros(len(my_data.index), np.float64))\n",
    "my_data['recent_min_score'] = pd.Series(np.zeros(len(my_data.index), np.float64))\n",
    "my_data['recent_avg_controversiality'] = pd.Series(np.zeros(len(my_data.index), np.float64))\n",
    "my_data['recent_avg_ups'] = pd.Series(np.zeros(len(my_data.index), np.float64))\n",
    "my_data['recent_avg_diff_ratio'] = pd.Series(np.zeros(len(my_data.index), np.float64))\n",
    "my_data['recent_max_diff_ratio'] = pd.Series(np.zeros(len(my_data.index), np.float64))\n",
    "my_data['recent_avg_sentiment_polarity'] = pd.Series(np.zeros(len(my_data.index), np.float64))\n",
    "my_data['recent_min_sentiment_polarity'] = pd.Series(np.zeros(len(my_data.index), np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count num of bots and trolls\n",
    "bots = my_data['is_bot']\n",
    "trolls = my_data['is_troll']\n",
    "normies = my_data[(my_data.is_bot == False) & (my_data.is_troll == False)]\n",
    "print(\"Number of bot comments: \", bots.sum())\n",
    "print(\"Number of troll comments:\", trolls.sum())\n",
    "print(\"Number of normal comments:\", len(normies))\n",
    "\n",
    "bot_authors = my_data[my_data['is_bot'] == True][['author']]\n",
    "troll_authors = my_data[my_data['is_troll'] == True][['author']]\n",
    "print(\"Number of bot authors: \", len(np.unique(bot_authors)))\n",
    "print(\"Number of troll authors:\", len(np.unique(troll_authors)))\n",
    "\n",
    "# Num of users\n",
    "users = my_data['author'].values\n",
    "num_of_users = np.unique(users)\n",
    "print(\"Number of total authors: \", len(num_of_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_ratio(_a, _b):\n",
    "    return difflib.SequenceMatcher(a=_a,b=_b).ratio()\n",
    "\n",
    "def last_30(a, b):\n",
    "    return a - dt.timedelta(days=30) < pd.to_datetime(b, unit='s')\n",
    "\n",
    "num = 0\n",
    "\n",
    "def calc_stats(comment):\n",
    "    # track progress\n",
    "    global num \n",
    "    num += 1\n",
    "    if(num % 1000 == 0): print(num)\n",
    "    recent_comments = pd.read_json(comment['recent_comments'], dtype={\n",
    "        \"banned_by\": str,\n",
    "        \"no_follow\": bool,\n",
    "        \"link_id\": str,\n",
    "        \"gilded\": np.float64,\n",
    "        \"author\": str,\n",
    "        \"author_verified\": bool,\n",
    "        \"author_comment_karma\": np.float64,\n",
    "        \"author_link_karma\": np.float64,\n",
    "        \"num_comments\": np.float64,\n",
    "        \"created_utc\": np.float64,\n",
    "        \"score\": np.float64,\n",
    "        \"over_18\": bool,\n",
    "        \"body\": str,\n",
    "        \"downs\": np.float64,\n",
    "        \"is_submitter\": bool,\n",
    "        \"num_reports\": np.float64,\n",
    "        \"controversiality\": np.float64,\n",
    "        \"quarantine\": bool,\n",
    "        \"ups\": np.float64})\n",
    "    if(len(recent_comments) > 0):\n",
    "        comment['recent_num_comments'] = len(recent_comments)\n",
    "        comment['recent_num_last_30_days'] = recent_comments['created_utc'].apply(lambda x: last_30(comment['created_utc'], x)).sum()\n",
    "        comment['recent_avg_no_follow'] = recent_comments['no_follow'].mean()\n",
    "        comment['recent_avg_gilded'] = recent_comments['gilded'].mean()\n",
    "        comment['recent_avg_responses'] = recent_comments['num_comments'].mean()\n",
    "        comment['recent_percent_neg_score'] = recent_comments['score'].apply(lambda x: x < 0).mean() * 100\n",
    "        comment['recent_avg_score'] = recent_comments['score'].mean()\n",
    "        comment['recent_min_score'] = recent_comments['score'].min()\n",
    "        comment['recent_avg_controversiality'] = recent_comments['controversiality'].mean()\n",
    "        comment['recent_avg_ups'] = recent_comments['ups'].mean()\n",
    "        diff = recent_comments['body'].str.slice(stop=200).fillna('').apply(lambda x: diff_ratio(comment['body'], x))\n",
    "        comment['recent_avg_diff_ratio'] = diff.mean()\n",
    "        comment['recent_max_diff_ratio'] = diff.max()\n",
    "        scores = recent_comments['body'].append(pd.Series(comment['body'])).apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "        comment['recent_avg_sentiment_polarity'] = scores.mean()\n",
    "        comment['recent_min_sentiment_polarity'] = scores.min()\n",
    "        \n",
    "    return comment\n",
    "\n",
    "new_data = my_data.apply(calc_stats, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['target'] = 'normal'\n",
    "\n",
    "# Delete is_bot and is_troll collumns and add targets column\n",
    "columns = ['is_bot', 'is_troll']\n",
    "new_data.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "# Delete recent_comments to save space\n",
    "columns = ['recent_comments']\n",
    "new_data.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "new_data.to_csv('lib/data/my_clean_data_normies.csv', sep=',', index=False)\n",
    "print(\"The data cleaning finished correctly!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botidentification",
   "language": "python",
   "name": "botidentification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
